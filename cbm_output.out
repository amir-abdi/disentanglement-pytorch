name=slurm_script
Pre-Processing CelebA
Created the simple conv64 with channels 3
Initialized CBM_Join model
Created the simple conv64 with channels 3
<class 'argparse.Namespace'>
## Initializing Train indexes
::path chosen -> logs/celebA__CBM_Join__2022_04/07-14/train_runs
Losses: {'total_vae': tensor(2.9858, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.6928, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.         1.         0.69277233 0.         0.89917088]]
[0:374]  loss_total_vae=0.447  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.446  loss_total_vae_epoch=0.507  
Losses: {'total_vae': tensor(0.4447, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.4436, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.         1.         0.69277233 0.         0.89917088]
 [1.         2.         0.44363075 0.         3.01528788]]
[1:749]  loss_total_vae=0.342  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.341  loss_total_vae_epoch=0.412  
Losses: {'total_vae': tensor(0.3504, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.3500, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.         1.         0.69277233 0.         0.89917088]
 [1.         2.         0.44363075 0.         3.01528788]
 [1.         3.         0.35002869 0.         3.39058685]]
[2:1124]  loss_total_vae=0.307  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.307  loss_total_vae_epoch=0.322  
Losses: {'total_vae': tensor(0.3039, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.3037, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.         1.         0.69277233 0.         0.89917088]
 [1.         2.         0.44363075 0.         3.01528788]
 [1.         3.         0.35002869 0.         3.39058685]
 [1.         4.         0.30367833 0.         3.48947883]]
[3:1499]  loss_total_vae=0.290  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.290  loss_total_vae_epoch=0.293  
Losses: {'total_vae': tensor(0.2900, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2899, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.         1.         0.69277233 0.         0.89917088]
 [1.         2.         0.44363075 0.         3.01528788]
 [1.         3.         0.35002869 0.         3.39058685]
 [1.         4.         0.30367833 0.         3.48947883]
 [1.         5.         0.28990892 0.         3.99559569]]
[4:1874]  loss_total_vae=0.267  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.267  loss_total_vae_epoch=0.277  
Losses: {'total_vae': tensor(0.2596, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2595, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.         1.         0.69277233 0.         0.89917088]
 [1.         2.         0.44363075 0.         3.01528788]
 [1.         3.         0.35002869 0.         3.39058685]
 [1.         4.         0.30367833 0.         3.48947883]
 [1.         5.         0.28990892 0.         3.99559569]
 [1.         6.         0.2595005  0.         4.02565432]]
[5:2249]  loss_total_vae=0.277  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.277  loss_total_vae_epoch=0.266  
Losses: {'total_vae': tensor(0.2565, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2565, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.         1.         0.69277233 0.         0.89917088]
 [1.         2.         0.44363075 0.         3.01528788]
 [1.         3.         0.35002869 0.         3.39058685]
 [1.         4.         0.30367833 0.         3.48947883]
 [1.         5.         0.28990892 0.         3.99559569]
 [1.         6.         0.2595005  0.         4.02565432]
 [1.         7.         0.2564806  0.         3.94813323]]
[6:2624]  loss_total_vae=0.242  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.242  loss_total_vae_epoch=0.257  
Losses: {'total_vae': tensor(0.2393, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2392, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.         1.         0.69277233 0.         0.89917088]
 [1.         2.         0.44363075 0.         3.01528788]
 [1.         3.         0.35002869 0.         3.39058685]
 [1.         4.         0.30367833 0.         3.48947883]
 [1.         5.         0.28990892 0.         3.99559569]
 [1.         6.         0.2595005  0.         4.02565432]
 [1.         7.         0.2564806  0.         3.94813323]
 [1.         8.         0.23923457 0.         4.01442099]]
[7:2999]  loss_total_vae=0.247  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.247  loss_total_vae_epoch=0.250  
Losses: {'total_vae': tensor(0.2280, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2280, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.         1.         0.69277233 0.         0.89917088]
 [1.         2.         0.44363075 0.         3.01528788]
 [1.         3.         0.35002869 0.         3.39058685]
 [1.         4.         0.30367833 0.         3.48947883]
 [1.         5.         0.28990892 0.         3.99559569]
 [1.         6.         0.2595005  0.         4.02565432]
 [1.         7.         0.2564806  0.         3.94813323]
 [1.         8.         0.23923457 0.         4.01442099]
 [1.         9.         0.22797716 0.         4.22430038]]
[8:3374]  loss_total_vae=0.254  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.254  loss_total_vae_epoch=0.243  
Losses: {'total_vae': tensor(0.2374, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2374, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]]
[9:3749]  loss_total_vae=0.228  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.227  loss_total_vae_epoch=0.236  
Losses: {'total_vae': tensor(0.2169, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2169, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]]
[10:4124]  loss_total_vae=0.229  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.229  loss_total_vae_epoch=0.229  
Losses: {'total_vae': tensor(0.2204, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2204, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]]
[11:4499]  loss_total_vae=0.227  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.227  loss_total_vae_epoch=0.222  
Losses: {'total_vae': tensor(0.2091, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2091, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]]
[12:4874]  loss_total_vae=0.213  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.213  loss_total_vae_epoch=0.214  
Losses: {'total_vae': tensor(0.2044, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2044, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]]
[13:5249]  loss_total_vae=0.219  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.219  loss_total_vae_epoch=0.206  
Losses: {'total_vae': tensor(0.1897, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1897, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]]
[14:5624]  loss_total_vae=0.219  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.219  loss_total_vae_epoch=0.198  
Losses: {'total_vae': tensor(0.1795, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1795, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]]
[15:5999]  loss_total_vae=0.187  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.187  loss_total_vae_epoch=0.188  
Losses: {'total_vae': tensor(0.1687, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1687, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]]
[16:6374]  loss_total_vae=0.186  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.186  loss_total_vae_epoch=0.179  
Losses: {'total_vae': tensor(0.1744, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1744, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]]
[17:6749]  loss_total_vae=0.170  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.170  loss_total_vae_epoch=0.168  
Losses: {'total_vae': tensor(0.1535, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1535, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]]
[18:7124]  loss_total_vae=0.169  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.169  loss_total_vae_epoch=0.158  
Losses: {'total_vae': tensor(0.1461, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1461, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]]
[19:7499]  loss_total_vae=0.146  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.146  loss_total_vae_epoch=0.147  
Losses: {'total_vae': tensor(0.1201, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1201, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]]
[20:7874]  loss_total_vae=0.145  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.145  loss_total_vae_epoch=0.136  
Losses: {'total_vae': tensor(0.1199, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1199, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]]
[21:8249]  loss_total_vae=0.129  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.129  loss_total_vae_epoch=0.126  
Losses: {'total_vae': tensor(0.1171, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1171, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]]
[22:8624]  loss_total_vae=0.127  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.127  loss_total_vae_epoch=0.116  
Losses: {'total_vae': tensor(0.0994, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0994, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]]
[23:8999]  loss_total_vae=0.117  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.117  loss_total_vae_epoch=0.107  
Losses: {'total_vae': tensor(0.0858, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0858, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]]
[24:9374]  loss_total_vae=0.106  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.106  loss_total_vae_epoch=0.099  
Losses: {'total_vae': tensor(0.0864, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0864, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]]
[25:9749]  loss_total_vae=0.433  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.433  loss_total_vae_epoch=0.120  
Losses: {'total_vae': tensor(0.4135, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.4135, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]]
[26:10124]  loss_total_vae=0.309  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.309  loss_total_vae_epoch=0.337  
Losses: {'total_vae': tensor(0.3093, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.3093, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]]
[27:10499]  loss_total_vae=0.296  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.296  loss_total_vae_epoch=0.300  
Losses: {'total_vae': tensor(0.2867, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2867, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]]
[28:10874]  loss_total_vae=0.300  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.300  loss_total_vae_epoch=0.287  
Losses: {'total_vae': tensor(0.2776, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2776, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]]
[29:11249]  loss_total_vae=0.267  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.267  loss_total_vae_epoch=0.278  
Losses: {'total_vae': tensor(0.2607, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2607, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]]
[30:11624]  loss_total_vae=0.271  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.271  loss_total_vae_epoch=0.271  
Losses: {'total_vae': tensor(0.2638, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2638, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]]
[31:11999]  loss_total_vae=0.246  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.246  loss_total_vae_epoch=0.264  
Losses: {'total_vae': tensor(0.2582, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2582, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]]
[32:12374]  loss_total_vae=0.244  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.244  loss_total_vae_epoch=0.258  
Losses: {'total_vae': tensor(0.2545, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2545, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]]
[33:12749]  loss_total_vae=0.251  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.251  loss_total_vae_epoch=0.252  
Losses: {'total_vae': tensor(0.2392, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2392, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]]
[34:13124]  loss_total_vae=0.252  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.252  loss_total_vae_epoch=0.247  
Losses: {'total_vae': tensor(0.2323, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2323, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]]
[35:13499]  loss_total_vae=0.256  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.256  loss_total_vae_epoch=0.241  
Losses: {'total_vae': tensor(0.2410, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2410, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]]
[36:13874]  loss_total_vae=0.233  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.233  loss_total_vae_epoch=0.234  
Losses: {'total_vae': tensor(0.2453, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2453, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]]
[37:14249]  loss_total_vae=0.245  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.245  loss_total_vae_epoch=0.228  
Losses: {'total_vae': tensor(0.2192, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2192, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]]
[38:14624]  loss_total_vae=0.210  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.210  loss_total_vae_epoch=0.222  
Losses: {'total_vae': tensor(0.2023, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2023, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]]
[39:14999]  loss_total_vae=0.211  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.211  loss_total_vae_epoch=0.215  
Losses: {'total_vae': tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2167, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]]
[40:15374]  loss_total_vae=0.213  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.213  loss_total_vae_epoch=0.209  
Losses: {'total_vae': tensor(0.2025, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.2025, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]]
[41:15749]  loss_total_vae=0.208  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.208  loss_total_vae_epoch=0.202  
Losses: {'total_vae': tensor(0.1916, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1916, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]]
[42:16124]  loss_total_vae=0.198  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.198  loss_total_vae_epoch=0.195  
Losses: {'total_vae': tensor(0.1891, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1891, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]]
[43:16499]  loss_total_vae=0.195  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.195  loss_total_vae_epoch=0.189  
Losses: {'total_vae': tensor(0.1702, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1702, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]]
[44:16874]  loss_total_vae=0.167  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.167  loss_total_vae_epoch=0.182  
Losses: {'total_vae': tensor(0.1854, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1854, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]]
[45:17249]  loss_total_vae=0.168  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.168  loss_total_vae_epoch=0.177  
Losses: {'total_vae': tensor(0.1717, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1717, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]]
[46:17624]  loss_total_vae=0.183  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.183  loss_total_vae_epoch=0.170  
Losses: {'total_vae': tensor(0.1520, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1520, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]]
[47:17999]  loss_total_vae=0.164  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.164  loss_total_vae_epoch=0.165  
Losses: {'total_vae': tensor(0.1562, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1562, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]]
[48:18374]  loss_total_vae=0.159  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.159  loss_total_vae_epoch=0.159  
Losses: {'total_vae': tensor(0.1711, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1711, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]]
[49:18749]  loss_total_vae=0.171  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.171  loss_total_vae_epoch=0.154  
Losses: {'total_vae': tensor(0.1340, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1340, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]]
[50:19124]  loss_total_vae=0.145  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.145  loss_total_vae_epoch=0.149  
Losses: {'total_vae': tensor(0.1395, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1395, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]]
[51:19499]  loss_total_vae=0.158  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.158  loss_total_vae_epoch=0.144  
Losses: {'total_vae': tensor(0.1389, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1389, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]]
[52:19874]  loss_total_vae=0.154  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.154  loss_total_vae_epoch=0.139  
Losses: {'total_vae': tensor(0.1260, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1260, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]]
[53:20249]  loss_total_vae=0.170  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.170  loss_total_vae_epoch=0.135  
Losses: {'total_vae': tensor(0.1291, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1291, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]]
[54:20624]  loss_total_vae=0.131  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.131  loss_total_vae_epoch=0.130  
Losses: {'total_vae': tensor(0.1251, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1251, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]]
[55:20999]  loss_total_vae=0.143  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.143  loss_total_vae_epoch=0.126  
Losses: {'total_vae': tensor(0.1173, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1173, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]]
[56:21374]  loss_total_vae=0.123  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.123  loss_total_vae_epoch=0.122  
Losses: {'total_vae': tensor(0.0929, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0929, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]]
[57:21749]  loss_total_vae=0.134  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.134  loss_total_vae_epoch=0.118  
Losses: {'total_vae': tensor(0.1191, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1191, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]]
[58:22124]  loss_total_vae=0.113  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.113  loss_total_vae_epoch=0.115  
Losses: {'total_vae': tensor(0.1001, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1001, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]]
[59:22499]  loss_total_vae=0.107  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.107  loss_total_vae_epoch=0.112  
Losses: {'total_vae': tensor(0.1025, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1025, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]]
[60:22874]  loss_total_vae=0.128  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.128  loss_total_vae_epoch=0.108  
Losses: {'total_vae': tensor(0.0969, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0969, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]]
[61:23249]  loss_total_vae=0.100  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.100  loss_total_vae_epoch=0.105  
Losses: {'total_vae': tensor(0.0881, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0881, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]]
[62:23624]  loss_total_vae=0.086  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.086  loss_total_vae_epoch=0.100  
Losses: {'total_vae': tensor(0.0917, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0917, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]
 [ 1.         64.          0.09172367  0.          9.21248531]]
[63:23999]  loss_total_vae=0.112  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.112  loss_total_vae_epoch=0.098  
Losses: {'total_vae': tensor(0.0957, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0957, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]
 [ 1.         64.          0.09172367  0.          9.21248531]
 [ 1.         65.          0.09572305  0.          9.67524147]]
[64:24374]  loss_total_vae=0.102  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.102  loss_total_vae_epoch=0.096  
Losses: {'total_vae': tensor(0.0895, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0895, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]
 [ 1.         64.          0.09172367  0.          9.21248531]
 [ 1.         65.          0.09572305  0.          9.67524147]
 [ 1.         66.          0.08950805  0.          9.5928421 ]]
[65:24749]  loss_total_vae=0.099  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.099  loss_total_vae_epoch=0.093  
Losses: {'total_vae': tensor(0.0963, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0963, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]
 [ 1.         64.          0.09172367  0.          9.21248531]
 [ 1.         65.          0.09572305  0.          9.67524147]
 [ 1.         66.          0.08950805  0.          9.5928421 ]
 [ 1.         67.          0.09632027  0.          9.78663254]]
[66:25124]  loss_total_vae=0.100  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.100  loss_total_vae_epoch=0.091  
Losses: {'total_vae': tensor(0.1122, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.1122, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]
 [ 1.         64.          0.09172367  0.          9.21248531]
 [ 1.         65.          0.09572305  0.          9.67524147]
 [ 1.         66.          0.08950805  0.          9.5928421 ]
 [ 1.         67.          0.09632027  0.          9.78663254]
 [ 1.         68.          0.11215305  0.          9.68066406]]
[67:25499]  loss_total_vae=0.080  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.080  loss_total_vae_epoch=0.088  
Losses: {'total_vae': tensor(0.0758, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0758, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]
 [ 1.         64.          0.09172367  0.          9.21248531]
 [ 1.         65.          0.09572305  0.          9.67524147]
 [ 1.         66.          0.08950805  0.          9.5928421 ]
 [ 1.         67.          0.09632027  0.          9.78663254]
 [ 1.         68.          0.11215305  0.          9.68066406]
 [ 1.         69.          0.07583032  0.          9.66231441]]
[68:25874]  loss_total_vae=0.089  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.089  loss_total_vae_epoch=0.084  
Losses: {'total_vae': tensor(0.0838, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0838, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]
 [ 1.         64.          0.09172367  0.          9.21248531]
 [ 1.         65.          0.09572305  0.          9.67524147]
 [ 1.         66.          0.08950805  0.          9.5928421 ]
 [ 1.         67.          0.09632027  0.          9.78663254]
 [ 1.         68.          0.11215305  0.          9.68066406]
 [ 1.         69.          0.07583032  0.          9.66231441]
 [ 1.         70.          0.08375107  0.         10.10819149]]
[69:26249]  loss_total_vae=0.096  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.096  loss_total_vae_epoch=0.082  
Losses: {'total_vae': tensor(0.0725, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0725, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]
 [ 1.         64.          0.09172367  0.          9.21248531]
 [ 1.         65.          0.09572305  0.          9.67524147]
 [ 1.         66.          0.08950805  0.          9.5928421 ]
 [ 1.         67.          0.09632027  0.          9.78663254]
 [ 1.         68.          0.11215305  0.          9.68066406]
 [ 1.         69.          0.07583032  0.          9.66231441]
 [ 1.         70.          0.08375107  0.         10.10819149]
 [ 1.         71.          0.07246029  0.         10.70610714]]
[70:26624]  loss_total_vae=0.083  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.083  loss_total_vae_epoch=0.081  
Losses: {'total_vae': tensor(0.0822, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0822, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[ 1.          1.          0.69277233  0.          0.89917088]
 [ 1.          2.          0.44363075  0.          3.01528788]
 [ 1.          3.          0.35002869  0.          3.39058685]
 [ 1.          4.          0.30367833  0.          3.48947883]
 [ 1.          5.          0.28990892  0.          3.99559569]
 [ 1.          6.          0.2595005   0.          4.02565432]
 [ 1.          7.          0.2564806   0.          3.94813323]
 [ 1.          8.          0.23923457  0.          4.01442099]
 [ 1.          9.          0.22797716  0.          4.22430038]
 [ 1.         10.          0.23735234  0.          4.43185425]
 [ 1.         11.          0.21692748  0.          4.50525761]
 [ 1.         12.          0.22036323  0.          4.44228792]
 [ 1.         13.          0.20906839  0.          4.66179037]
 [ 1.         14.          0.20435777  0.          4.48139954]
 [ 1.         15.          0.1897275   0.          4.67815495]
 [ 1.         16.          0.17950806  0.          4.68066502]
 [ 1.         17.          0.16869529  0.          4.85452175]
 [ 1.         18.          0.17436758  0.          4.83069229]
 [ 1.         19.          0.15347296  0.          4.9044528 ]
 [ 1.         20.          0.14608137  0.          4.96000528]
 [ 1.         21.          0.12012215  0.          5.14042282]
 [ 1.         22.          0.1198969   0.          5.07718039]
 [ 1.         23.          0.11712976  0.          5.14670515]
 [ 1.         24.          0.09942244  0.          5.22992277]
 [ 1.         25.          0.08583003  0.          5.18132925]
 [ 1.         26.          0.08642785  0.          5.35614824]
 [ 1.         27.          0.41345796  0.          5.09576797]
 [ 1.         28.          0.3092573   0.          5.5306859 ]
 [ 1.         29.          0.28667128  0.          5.83729553]
 [ 1.         30.          0.27755675  0.          5.50498629]
 [ 1.         31.          0.26072878  0.          5.67329884]
 [ 1.         32.          0.26377103  0.          5.72911453]
 [ 1.         33.          0.25815114  0.          6.00071096]
 [ 1.         34.          0.25453112  0.          5.85542822]
 [ 1.         35.          0.23921311  0.          6.02575207]
 [ 1.         36.          0.23227759  0.          6.24313211]
 [ 1.         37.          0.24102864  0.          6.13102484]
 [ 1.         38.          0.24528015  0.          6.36832666]
 [ 1.         39.          0.21916123  0.          6.25614166]
 [ 1.         40.          0.20228545  0.          6.20438337]
 [ 1.         41.          0.21671204  0.          6.66814423]
 [ 1.         42.          0.20245977  0.          6.96894217]
 [ 1.         43.          0.19164301  0.          6.8403163 ]
 [ 1.         44.          0.18907872  0.          6.83900452]
 [ 1.         45.          0.17017892  0.          6.96279526]
 [ 1.         46.          0.18544655  0.          7.36610126]
 [ 1.         47.          0.1717089   0.          7.06800699]
 [ 1.         48.          0.15201601  0.          7.42351675]
 [ 1.         49.          0.15618511  0.          7.46893406]
 [ 1.         50.          0.17107826  0.          8.00892639]
 [ 1.         51.          0.13395309  0.          7.73567677]
 [ 1.         52.          0.13946418  0.          7.88073301]
 [ 1.         53.          0.13892105  0.          8.11386204]
 [ 1.         54.          0.12604013  0.          7.90681171]
 [ 1.         55.          0.1291136   0.          8.39498425]
 [ 1.         56.          0.12505865  0.          8.03620815]
 [ 1.         57.          0.11731915  0.          8.48965359]
 [ 1.         58.          0.09294643  0.          9.03112698]
 [ 1.         59.          0.11910862  0.          8.71849632]
 [ 1.         60.          0.10010626  0.          9.25134563]
 [ 1.         61.          0.10251174  0.          8.64664745]
 [ 1.         62.          0.09691696  0.          9.07325649]
 [ 1.         63.          0.08812342  0.          9.20100975]
 [ 1.         64.          0.09172367  0.          9.21248531]
 [ 1.         65.          0.09572305  0.          9.67524147]
 [ 1.         66.          0.08950805  0.          9.5928421 ]
 [ 1.         67.          0.09632027  0.          9.78663254]
 [ 1.         68.          0.11215305  0.          9.68066406]
 [ 1.         69.          0.07583032  0.          9.66231441]
 [ 1.         70.          0.08375107  0.         10.10819149]
 [ 1.         71.          0.07246029  0.         10.70610714]
 [ 1.         72.          0.08220924  0.         10.01729298]]
[71:26999]  loss_total_vae=0.092  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.092  loss_total_vae_epoch=0.079  
Losses: {'total_vae': tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0721, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.00000000e+00 1.00000000e+00 6.92772329e-01 0.00000000e+00
  8.99170876e-01]
 [1.00000000e+00 2.00000000e+00 4.43630755e-01 0.00000000e+00
  3.01528788e+00]
 [1.00000000e+00 3.00000000e+00 3.50028694e-01 0.00000000e+00
  3.39058685e+00]
 [1.00000000e+00 4.00000000e+00 3.03678334e-01 0.00000000e+00
  3.48947883e+00]
 [1.00000000e+00 5.00000000e+00 2.89908916e-01 0.00000000e+00
  3.99559569e+00]
 [1.00000000e+00 6.00000000e+00 2.59500504e-01 0.00000000e+00
  4.02565432e+00]
 [1.00000000e+00 7.00000000e+00 2.56480604e-01 0.00000000e+00
  3.94813323e+00]
 [1.00000000e+00 8.00000000e+00 2.39234567e-01 0.00000000e+00
  4.01442099e+00]
 [1.00000000e+00 9.00000000e+00 2.27977157e-01 0.00000000e+00
  4.22430038e+00]
 [1.00000000e+00 1.00000000e+01 2.37352341e-01 0.00000000e+00
  4.43185425e+00]
 [1.00000000e+00 1.10000000e+01 2.16927484e-01 0.00000000e+00
  4.50525761e+00]
 [1.00000000e+00 1.20000000e+01 2.20363230e-01 0.00000000e+00
  4.44228792e+00]
 [1.00000000e+00 1.30000000e+01 2.09068388e-01 0.00000000e+00
  4.66179037e+00]
 [1.00000000e+00 1.40000000e+01 2.04357773e-01 0.00000000e+00
  4.48139954e+00]
 [1.00000000e+00 1.50000000e+01 1.89727500e-01 0.00000000e+00
  4.67815495e+00]
 [1.00000000e+00 1.60000000e+01 1.79508060e-01 0.00000000e+00
  4.68066502e+00]
 [1.00000000e+00 1.70000000e+01 1.68695286e-01 0.00000000e+00
  4.85452175e+00]
 [1.00000000e+00 1.80000000e+01 1.74367577e-01 0.00000000e+00
  4.83069229e+00]
 [1.00000000e+00 1.90000000e+01 1.53472960e-01 0.00000000e+00
  4.90445280e+00]
 [1.00000000e+00 2.00000000e+01 1.46081373e-01 0.00000000e+00
  4.96000528e+00]
 [1.00000000e+00 2.10000000e+01 1.20122150e-01 0.00000000e+00
  5.14042282e+00]
 [1.00000000e+00 2.20000000e+01 1.19896904e-01 0.00000000e+00
  5.07718039e+00]
 [1.00000000e+00 2.30000000e+01 1.17129758e-01 0.00000000e+00
  5.14670515e+00]
 [1.00000000e+00 2.40000000e+01 9.94224399e-02 0.00000000e+00
  5.22992277e+00]
 [1.00000000e+00 2.50000000e+01 8.58300328e-02 0.00000000e+00
  5.18132925e+00]
 [1.00000000e+00 2.60000000e+01 8.64278525e-02 0.00000000e+00
  5.35614824e+00]
 [1.00000000e+00 2.70000000e+01 4.13457960e-01 0.00000000e+00
  5.09576797e+00]
 [1.00000000e+00 2.80000000e+01 3.09257299e-01 0.00000000e+00
  5.53068590e+00]
 [1.00000000e+00 2.90000000e+01 2.86671281e-01 0.00000000e+00
  5.83729553e+00]
 [1.00000000e+00 3.00000000e+01 2.77556747e-01 0.00000000e+00
  5.50498629e+00]
 [1.00000000e+00 3.10000000e+01 2.60728776e-01 0.00000000e+00
  5.67329884e+00]
 [1.00000000e+00 3.20000000e+01 2.63771027e-01 0.00000000e+00
  5.72911453e+00]
 [1.00000000e+00 3.30000000e+01 2.58151144e-01 0.00000000e+00
  6.00071096e+00]
 [1.00000000e+00 3.40000000e+01 2.54531115e-01 0.00000000e+00
  5.85542822e+00]
 [1.00000000e+00 3.50000000e+01 2.39213109e-01 0.00000000e+00
  6.02575207e+00]
 [1.00000000e+00 3.60000000e+01 2.32277587e-01 0.00000000e+00
  6.24313211e+00]
 [1.00000000e+00 3.70000000e+01 2.41028637e-01 0.00000000e+00
  6.13102484e+00]
 [1.00000000e+00 3.80000000e+01 2.45280147e-01 0.00000000e+00
  6.36832666e+00]
 [1.00000000e+00 3.90000000e+01 2.19161227e-01 0.00000000e+00
  6.25614166e+00]
 [1.00000000e+00 4.00000000e+01 2.02285454e-01 0.00000000e+00
  6.20438337e+00]
 [1.00000000e+00 4.10000000e+01 2.16712043e-01 0.00000000e+00
  6.66814423e+00]
 [1.00000000e+00 4.20000000e+01 2.02459767e-01 0.00000000e+00
  6.96894217e+00]
 [1.00000000e+00 4.30000000e+01 1.91643015e-01 0.00000000e+00
  6.84031630e+00]
 [1.00000000e+00 4.40000000e+01 1.89078718e-01 0.00000000e+00
  6.83900452e+00]
 [1.00000000e+00 4.50000000e+01 1.70178920e-01 0.00000000e+00
  6.96279526e+00]
 [1.00000000e+00 4.60000000e+01 1.85446545e-01 0.00000000e+00
  7.36610126e+00]
 [1.00000000e+00 4.70000000e+01 1.71708897e-01 0.00000000e+00
  7.06800699e+00]
 [1.00000000e+00 4.80000000e+01 1.52016014e-01 0.00000000e+00
  7.42351675e+00]
 [1.00000000e+00 4.90000000e+01 1.56185105e-01 0.00000000e+00
  7.46893406e+00]
 [1.00000000e+00 5.00000000e+01 1.71078265e-01 0.00000000e+00
  8.00892639e+00]
 [1.00000000e+00 5.10000000e+01 1.33953094e-01 0.00000000e+00
  7.73567677e+00]
 [1.00000000e+00 5.20000000e+01 1.39464185e-01 0.00000000e+00
  7.88073301e+00]
 [1.00000000e+00 5.30000000e+01 1.38921052e-01 0.00000000e+00
  8.11386204e+00]
 [1.00000000e+00 5.40000000e+01 1.26040131e-01 0.00000000e+00
  7.90681171e+00]
 [1.00000000e+00 5.50000000e+01 1.29113600e-01 0.00000000e+00
  8.39498425e+00]
 [1.00000000e+00 5.60000000e+01 1.25058651e-01 0.00000000e+00
  8.03620815e+00]
 [1.00000000e+00 5.70000000e+01 1.17319152e-01 0.00000000e+00
  8.48965359e+00]
 [1.00000000e+00 5.80000000e+01 9.29464251e-02 0.00000000e+00
  9.03112698e+00]
 [1.00000000e+00 5.90000000e+01 1.19108617e-01 0.00000000e+00
  8.71849632e+00]
 [1.00000000e+00 6.00000000e+01 1.00106262e-01 0.00000000e+00
  9.25134563e+00]
 [1.00000000e+00 6.10000000e+01 1.02511741e-01 0.00000000e+00
  8.64664745e+00]
 [1.00000000e+00 6.20000000e+01 9.69169587e-02 0.00000000e+00
  9.07325649e+00]
 [1.00000000e+00 6.30000000e+01 8.81234184e-02 0.00000000e+00
  9.20100975e+00]
 [1.00000000e+00 6.40000000e+01 9.17236656e-02 0.00000000e+00
  9.21248531e+00]
 [1.00000000e+00 6.50000000e+01 9.57230479e-02 0.00000000e+00
  9.67524147e+00]
 [1.00000000e+00 6.60000000e+01 8.95080492e-02 0.00000000e+00
  9.59284210e+00]
 [1.00000000e+00 6.70000000e+01 9.63202715e-02 0.00000000e+00
  9.78663254e+00]
 [1.00000000e+00 6.80000000e+01 1.12153053e-01 0.00000000e+00
  9.68066406e+00]
 [1.00000000e+00 6.90000000e+01 7.58303180e-02 0.00000000e+00
  9.66231441e+00]
 [1.00000000e+00 7.00000000e+01 8.37510750e-02 0.00000000e+00
  1.01081915e+01]
 [1.00000000e+00 7.10000000e+01 7.24602938e-02 0.00000000e+00
  1.07061071e+01]
 [1.00000000e+00 7.20000000e+01 8.22092444e-02 0.00000000e+00
  1.00172930e+01]
 [1.00000000e+00 7.30000000e+01 7.21338093e-02 0.00000000e+00
  1.03673401e+01]]
[72:27374]  loss_total_vae=0.070  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.070  loss_total_vae_epoch=0.076  
Losses: {'total_vae': tensor(0.0744, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0744, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.00000000e+00 1.00000000e+00 6.92772329e-01 0.00000000e+00
  8.99170876e-01]
 [1.00000000e+00 2.00000000e+00 4.43630755e-01 0.00000000e+00
  3.01528788e+00]
 [1.00000000e+00 3.00000000e+00 3.50028694e-01 0.00000000e+00
  3.39058685e+00]
 [1.00000000e+00 4.00000000e+00 3.03678334e-01 0.00000000e+00
  3.48947883e+00]
 [1.00000000e+00 5.00000000e+00 2.89908916e-01 0.00000000e+00
  3.99559569e+00]
 [1.00000000e+00 6.00000000e+00 2.59500504e-01 0.00000000e+00
  4.02565432e+00]
 [1.00000000e+00 7.00000000e+00 2.56480604e-01 0.00000000e+00
  3.94813323e+00]
 [1.00000000e+00 8.00000000e+00 2.39234567e-01 0.00000000e+00
  4.01442099e+00]
 [1.00000000e+00 9.00000000e+00 2.27977157e-01 0.00000000e+00
  4.22430038e+00]
 [1.00000000e+00 1.00000000e+01 2.37352341e-01 0.00000000e+00
  4.43185425e+00]
 [1.00000000e+00 1.10000000e+01 2.16927484e-01 0.00000000e+00
  4.50525761e+00]
 [1.00000000e+00 1.20000000e+01 2.20363230e-01 0.00000000e+00
  4.44228792e+00]
 [1.00000000e+00 1.30000000e+01 2.09068388e-01 0.00000000e+00
  4.66179037e+00]
 [1.00000000e+00 1.40000000e+01 2.04357773e-01 0.00000000e+00
  4.48139954e+00]
 [1.00000000e+00 1.50000000e+01 1.89727500e-01 0.00000000e+00
  4.67815495e+00]
 [1.00000000e+00 1.60000000e+01 1.79508060e-01 0.00000000e+00
  4.68066502e+00]
 [1.00000000e+00 1.70000000e+01 1.68695286e-01 0.00000000e+00
  4.85452175e+00]
 [1.00000000e+00 1.80000000e+01 1.74367577e-01 0.00000000e+00
  4.83069229e+00]
 [1.00000000e+00 1.90000000e+01 1.53472960e-01 0.00000000e+00
  4.90445280e+00]
 [1.00000000e+00 2.00000000e+01 1.46081373e-01 0.00000000e+00
  4.96000528e+00]
 [1.00000000e+00 2.10000000e+01 1.20122150e-01 0.00000000e+00
  5.14042282e+00]
 [1.00000000e+00 2.20000000e+01 1.19896904e-01 0.00000000e+00
  5.07718039e+00]
 [1.00000000e+00 2.30000000e+01 1.17129758e-01 0.00000000e+00
  5.14670515e+00]
 [1.00000000e+00 2.40000000e+01 9.94224399e-02 0.00000000e+00
  5.22992277e+00]
 [1.00000000e+00 2.50000000e+01 8.58300328e-02 0.00000000e+00
  5.18132925e+00]
 [1.00000000e+00 2.60000000e+01 8.64278525e-02 0.00000000e+00
  5.35614824e+00]
 [1.00000000e+00 2.70000000e+01 4.13457960e-01 0.00000000e+00
  5.09576797e+00]
 [1.00000000e+00 2.80000000e+01 3.09257299e-01 0.00000000e+00
  5.53068590e+00]
 [1.00000000e+00 2.90000000e+01 2.86671281e-01 0.00000000e+00
  5.83729553e+00]
 [1.00000000e+00 3.00000000e+01 2.77556747e-01 0.00000000e+00
  5.50498629e+00]
 [1.00000000e+00 3.10000000e+01 2.60728776e-01 0.00000000e+00
  5.67329884e+00]
 [1.00000000e+00 3.20000000e+01 2.63771027e-01 0.00000000e+00
  5.72911453e+00]
 [1.00000000e+00 3.30000000e+01 2.58151144e-01 0.00000000e+00
  6.00071096e+00]
 [1.00000000e+00 3.40000000e+01 2.54531115e-01 0.00000000e+00
  5.85542822e+00]
 [1.00000000e+00 3.50000000e+01 2.39213109e-01 0.00000000e+00
  6.02575207e+00]
 [1.00000000e+00 3.60000000e+01 2.32277587e-01 0.00000000e+00
  6.24313211e+00]
 [1.00000000e+00 3.70000000e+01 2.41028637e-01 0.00000000e+00
  6.13102484e+00]
 [1.00000000e+00 3.80000000e+01 2.45280147e-01 0.00000000e+00
  6.36832666e+00]
 [1.00000000e+00 3.90000000e+01 2.19161227e-01 0.00000000e+00
  6.25614166e+00]
 [1.00000000e+00 4.00000000e+01 2.02285454e-01 0.00000000e+00
  6.20438337e+00]
 [1.00000000e+00 4.10000000e+01 2.16712043e-01 0.00000000e+00
  6.66814423e+00]
 [1.00000000e+00 4.20000000e+01 2.02459767e-01 0.00000000e+00
  6.96894217e+00]
 [1.00000000e+00 4.30000000e+01 1.91643015e-01 0.00000000e+00
  6.84031630e+00]
 [1.00000000e+00 4.40000000e+01 1.89078718e-01 0.00000000e+00
  6.83900452e+00]
 [1.00000000e+00 4.50000000e+01 1.70178920e-01 0.00000000e+00
  6.96279526e+00]
 [1.00000000e+00 4.60000000e+01 1.85446545e-01 0.00000000e+00
  7.36610126e+00]
 [1.00000000e+00 4.70000000e+01 1.71708897e-01 0.00000000e+00
  7.06800699e+00]
 [1.00000000e+00 4.80000000e+01 1.52016014e-01 0.00000000e+00
  7.42351675e+00]
 [1.00000000e+00 4.90000000e+01 1.56185105e-01 0.00000000e+00
  7.46893406e+00]
 [1.00000000e+00 5.00000000e+01 1.71078265e-01 0.00000000e+00
  8.00892639e+00]
 [1.00000000e+00 5.10000000e+01 1.33953094e-01 0.00000000e+00
  7.73567677e+00]
 [1.00000000e+00 5.20000000e+01 1.39464185e-01 0.00000000e+00
  7.88073301e+00]
 [1.00000000e+00 5.30000000e+01 1.38921052e-01 0.00000000e+00
  8.11386204e+00]
 [1.00000000e+00 5.40000000e+01 1.26040131e-01 0.00000000e+00
  7.90681171e+00]
 [1.00000000e+00 5.50000000e+01 1.29113600e-01 0.00000000e+00
  8.39498425e+00]
 [1.00000000e+00 5.60000000e+01 1.25058651e-01 0.00000000e+00
  8.03620815e+00]
 [1.00000000e+00 5.70000000e+01 1.17319152e-01 0.00000000e+00
  8.48965359e+00]
 [1.00000000e+00 5.80000000e+01 9.29464251e-02 0.00000000e+00
  9.03112698e+00]
 [1.00000000e+00 5.90000000e+01 1.19108617e-01 0.00000000e+00
  8.71849632e+00]
 [1.00000000e+00 6.00000000e+01 1.00106262e-01 0.00000000e+00
  9.25134563e+00]
 [1.00000000e+00 6.10000000e+01 1.02511741e-01 0.00000000e+00
  8.64664745e+00]
 [1.00000000e+00 6.20000000e+01 9.69169587e-02 0.00000000e+00
  9.07325649e+00]
 [1.00000000e+00 6.30000000e+01 8.81234184e-02 0.00000000e+00
  9.20100975e+00]
 [1.00000000e+00 6.40000000e+01 9.17236656e-02 0.00000000e+00
  9.21248531e+00]
 [1.00000000e+00 6.50000000e+01 9.57230479e-02 0.00000000e+00
  9.67524147e+00]
 [1.00000000e+00 6.60000000e+01 8.95080492e-02 0.00000000e+00
  9.59284210e+00]
 [1.00000000e+00 6.70000000e+01 9.63202715e-02 0.00000000e+00
  9.78663254e+00]
 [1.00000000e+00 6.80000000e+01 1.12153053e-01 0.00000000e+00
  9.68066406e+00]
 [1.00000000e+00 6.90000000e+01 7.58303180e-02 0.00000000e+00
  9.66231441e+00]
 [1.00000000e+00 7.00000000e+01 8.37510750e-02 0.00000000e+00
  1.01081915e+01]
 [1.00000000e+00 7.10000000e+01 7.24602938e-02 0.00000000e+00
  1.07061071e+01]
 [1.00000000e+00 7.20000000e+01 8.22092444e-02 0.00000000e+00
  1.00172930e+01]
 [1.00000000e+00 7.30000000e+01 7.21338093e-02 0.00000000e+00
  1.03673401e+01]
 [1.00000000e+00 7.40000000e+01 7.43681416e-02 0.00000000e+00
  1.02724028e+01]]
[73:27749]  loss_total_vae=0.096  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.096  loss_total_vae_epoch=0.074  
Losses: {'total_vae': tensor(0.0809, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0809, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.00000000e+00 1.00000000e+00 6.92772329e-01 0.00000000e+00
  8.99170876e-01]
 [1.00000000e+00 2.00000000e+00 4.43630755e-01 0.00000000e+00
  3.01528788e+00]
 [1.00000000e+00 3.00000000e+00 3.50028694e-01 0.00000000e+00
  3.39058685e+00]
 [1.00000000e+00 4.00000000e+00 3.03678334e-01 0.00000000e+00
  3.48947883e+00]
 [1.00000000e+00 5.00000000e+00 2.89908916e-01 0.00000000e+00
  3.99559569e+00]
 [1.00000000e+00 6.00000000e+00 2.59500504e-01 0.00000000e+00
  4.02565432e+00]
 [1.00000000e+00 7.00000000e+00 2.56480604e-01 0.00000000e+00
  3.94813323e+00]
 [1.00000000e+00 8.00000000e+00 2.39234567e-01 0.00000000e+00
  4.01442099e+00]
 [1.00000000e+00 9.00000000e+00 2.27977157e-01 0.00000000e+00
  4.22430038e+00]
 [1.00000000e+00 1.00000000e+01 2.37352341e-01 0.00000000e+00
  4.43185425e+00]
 [1.00000000e+00 1.10000000e+01 2.16927484e-01 0.00000000e+00
  4.50525761e+00]
 [1.00000000e+00 1.20000000e+01 2.20363230e-01 0.00000000e+00
  4.44228792e+00]
 [1.00000000e+00 1.30000000e+01 2.09068388e-01 0.00000000e+00
  4.66179037e+00]
 [1.00000000e+00 1.40000000e+01 2.04357773e-01 0.00000000e+00
  4.48139954e+00]
 [1.00000000e+00 1.50000000e+01 1.89727500e-01 0.00000000e+00
  4.67815495e+00]
 [1.00000000e+00 1.60000000e+01 1.79508060e-01 0.00000000e+00
  4.68066502e+00]
 [1.00000000e+00 1.70000000e+01 1.68695286e-01 0.00000000e+00
  4.85452175e+00]
 [1.00000000e+00 1.80000000e+01 1.74367577e-01 0.00000000e+00
  4.83069229e+00]
 [1.00000000e+00 1.90000000e+01 1.53472960e-01 0.00000000e+00
  4.90445280e+00]
 [1.00000000e+00 2.00000000e+01 1.46081373e-01 0.00000000e+00
  4.96000528e+00]
 [1.00000000e+00 2.10000000e+01 1.20122150e-01 0.00000000e+00
  5.14042282e+00]
 [1.00000000e+00 2.20000000e+01 1.19896904e-01 0.00000000e+00
  5.07718039e+00]
 [1.00000000e+00 2.30000000e+01 1.17129758e-01 0.00000000e+00
  5.14670515e+00]
 [1.00000000e+00 2.40000000e+01 9.94224399e-02 0.00000000e+00
  5.22992277e+00]
 [1.00000000e+00 2.50000000e+01 8.58300328e-02 0.00000000e+00
  5.18132925e+00]
 [1.00000000e+00 2.60000000e+01 8.64278525e-02 0.00000000e+00
  5.35614824e+00]
 [1.00000000e+00 2.70000000e+01 4.13457960e-01 0.00000000e+00
  5.09576797e+00]
 [1.00000000e+00 2.80000000e+01 3.09257299e-01 0.00000000e+00
  5.53068590e+00]
 [1.00000000e+00 2.90000000e+01 2.86671281e-01 0.00000000e+00
  5.83729553e+00]
 [1.00000000e+00 3.00000000e+01 2.77556747e-01 0.00000000e+00
  5.50498629e+00]
 [1.00000000e+00 3.10000000e+01 2.60728776e-01 0.00000000e+00
  5.67329884e+00]
 [1.00000000e+00 3.20000000e+01 2.63771027e-01 0.00000000e+00
  5.72911453e+00]
 [1.00000000e+00 3.30000000e+01 2.58151144e-01 0.00000000e+00
  6.00071096e+00]
 [1.00000000e+00 3.40000000e+01 2.54531115e-01 0.00000000e+00
  5.85542822e+00]
 [1.00000000e+00 3.50000000e+01 2.39213109e-01 0.00000000e+00
  6.02575207e+00]
 [1.00000000e+00 3.60000000e+01 2.32277587e-01 0.00000000e+00
  6.24313211e+00]
 [1.00000000e+00 3.70000000e+01 2.41028637e-01 0.00000000e+00
  6.13102484e+00]
 [1.00000000e+00 3.80000000e+01 2.45280147e-01 0.00000000e+00
  6.36832666e+00]
 [1.00000000e+00 3.90000000e+01 2.19161227e-01 0.00000000e+00
  6.25614166e+00]
 [1.00000000e+00 4.00000000e+01 2.02285454e-01 0.00000000e+00
  6.20438337e+00]
 [1.00000000e+00 4.10000000e+01 2.16712043e-01 0.00000000e+00
  6.66814423e+00]
 [1.00000000e+00 4.20000000e+01 2.02459767e-01 0.00000000e+00
  6.96894217e+00]
 [1.00000000e+00 4.30000000e+01 1.91643015e-01 0.00000000e+00
  6.84031630e+00]
 [1.00000000e+00 4.40000000e+01 1.89078718e-01 0.00000000e+00
  6.83900452e+00]
 [1.00000000e+00 4.50000000e+01 1.70178920e-01 0.00000000e+00
  6.96279526e+00]
 [1.00000000e+00 4.60000000e+01 1.85446545e-01 0.00000000e+00
  7.36610126e+00]
 [1.00000000e+00 4.70000000e+01 1.71708897e-01 0.00000000e+00
  7.06800699e+00]
 [1.00000000e+00 4.80000000e+01 1.52016014e-01 0.00000000e+00
  7.42351675e+00]
 [1.00000000e+00 4.90000000e+01 1.56185105e-01 0.00000000e+00
  7.46893406e+00]
 [1.00000000e+00 5.00000000e+01 1.71078265e-01 0.00000000e+00
  8.00892639e+00]
 [1.00000000e+00 5.10000000e+01 1.33953094e-01 0.00000000e+00
  7.73567677e+00]
 [1.00000000e+00 5.20000000e+01 1.39464185e-01 0.00000000e+00
  7.88073301e+00]
 [1.00000000e+00 5.30000000e+01 1.38921052e-01 0.00000000e+00
  8.11386204e+00]
 [1.00000000e+00 5.40000000e+01 1.26040131e-01 0.00000000e+00
  7.90681171e+00]
 [1.00000000e+00 5.50000000e+01 1.29113600e-01 0.00000000e+00
  8.39498425e+00]
 [1.00000000e+00 5.60000000e+01 1.25058651e-01 0.00000000e+00
  8.03620815e+00]
 [1.00000000e+00 5.70000000e+01 1.17319152e-01 0.00000000e+00
  8.48965359e+00]
 [1.00000000e+00 5.80000000e+01 9.29464251e-02 0.00000000e+00
  9.03112698e+00]
 [1.00000000e+00 5.90000000e+01 1.19108617e-01 0.00000000e+00
  8.71849632e+00]
 [1.00000000e+00 6.00000000e+01 1.00106262e-01 0.00000000e+00
  9.25134563e+00]
 [1.00000000e+00 6.10000000e+01 1.02511741e-01 0.00000000e+00
  8.64664745e+00]
 [1.00000000e+00 6.20000000e+01 9.69169587e-02 0.00000000e+00
  9.07325649e+00]
 [1.00000000e+00 6.30000000e+01 8.81234184e-02 0.00000000e+00
  9.20100975e+00]
 [1.00000000e+00 6.40000000e+01 9.17236656e-02 0.00000000e+00
  9.21248531e+00]
 [1.00000000e+00 6.50000000e+01 9.57230479e-02 0.00000000e+00
  9.67524147e+00]
 [1.00000000e+00 6.60000000e+01 8.95080492e-02 0.00000000e+00
  9.59284210e+00]
 [1.00000000e+00 6.70000000e+01 9.63202715e-02 0.00000000e+00
  9.78663254e+00]
 [1.00000000e+00 6.80000000e+01 1.12153053e-01 0.00000000e+00
  9.68066406e+00]
 [1.00000000e+00 6.90000000e+01 7.58303180e-02 0.00000000e+00
  9.66231441e+00]
 [1.00000000e+00 7.00000000e+01 8.37510750e-02 0.00000000e+00
  1.01081915e+01]
 [1.00000000e+00 7.10000000e+01 7.24602938e-02 0.00000000e+00
  1.07061071e+01]
 [1.00000000e+00 7.20000000e+01 8.22092444e-02 0.00000000e+00
  1.00172930e+01]
 [1.00000000e+00 7.30000000e+01 7.21338093e-02 0.00000000e+00
  1.03673401e+01]
 [1.00000000e+00 7.40000000e+01 7.43681416e-02 0.00000000e+00
  1.02724028e+01]
 [1.00000000e+00 7.50000000e+01 8.09321851e-02 0.00000000e+00
  1.09349670e+01]]
[74:28124]  loss_total_vae=0.063  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.063  loss_total_vae_epoch=0.074  
Losses: {'total_vae': tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0658, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.00000000e+00 1.00000000e+00 6.92772329e-01 0.00000000e+00
  8.99170876e-01]
 [1.00000000e+00 2.00000000e+00 4.43630755e-01 0.00000000e+00
  3.01528788e+00]
 [1.00000000e+00 3.00000000e+00 3.50028694e-01 0.00000000e+00
  3.39058685e+00]
 [1.00000000e+00 4.00000000e+00 3.03678334e-01 0.00000000e+00
  3.48947883e+00]
 [1.00000000e+00 5.00000000e+00 2.89908916e-01 0.00000000e+00
  3.99559569e+00]
 [1.00000000e+00 6.00000000e+00 2.59500504e-01 0.00000000e+00
  4.02565432e+00]
 [1.00000000e+00 7.00000000e+00 2.56480604e-01 0.00000000e+00
  3.94813323e+00]
 [1.00000000e+00 8.00000000e+00 2.39234567e-01 0.00000000e+00
  4.01442099e+00]
 [1.00000000e+00 9.00000000e+00 2.27977157e-01 0.00000000e+00
  4.22430038e+00]
 [1.00000000e+00 1.00000000e+01 2.37352341e-01 0.00000000e+00
  4.43185425e+00]
 [1.00000000e+00 1.10000000e+01 2.16927484e-01 0.00000000e+00
  4.50525761e+00]
 [1.00000000e+00 1.20000000e+01 2.20363230e-01 0.00000000e+00
  4.44228792e+00]
 [1.00000000e+00 1.30000000e+01 2.09068388e-01 0.00000000e+00
  4.66179037e+00]
 [1.00000000e+00 1.40000000e+01 2.04357773e-01 0.00000000e+00
  4.48139954e+00]
 [1.00000000e+00 1.50000000e+01 1.89727500e-01 0.00000000e+00
  4.67815495e+00]
 [1.00000000e+00 1.60000000e+01 1.79508060e-01 0.00000000e+00
  4.68066502e+00]
 [1.00000000e+00 1.70000000e+01 1.68695286e-01 0.00000000e+00
  4.85452175e+00]
 [1.00000000e+00 1.80000000e+01 1.74367577e-01 0.00000000e+00
  4.83069229e+00]
 [1.00000000e+00 1.90000000e+01 1.53472960e-01 0.00000000e+00
  4.90445280e+00]
 [1.00000000e+00 2.00000000e+01 1.46081373e-01 0.00000000e+00
  4.96000528e+00]
 [1.00000000e+00 2.10000000e+01 1.20122150e-01 0.00000000e+00
  5.14042282e+00]
 [1.00000000e+00 2.20000000e+01 1.19896904e-01 0.00000000e+00
  5.07718039e+00]
 [1.00000000e+00 2.30000000e+01 1.17129758e-01 0.00000000e+00
  5.14670515e+00]
 [1.00000000e+00 2.40000000e+01 9.94224399e-02 0.00000000e+00
  5.22992277e+00]
 [1.00000000e+00 2.50000000e+01 8.58300328e-02 0.00000000e+00
  5.18132925e+00]
 [1.00000000e+00 2.60000000e+01 8.64278525e-02 0.00000000e+00
  5.35614824e+00]
 [1.00000000e+00 2.70000000e+01 4.13457960e-01 0.00000000e+00
  5.09576797e+00]
 [1.00000000e+00 2.80000000e+01 3.09257299e-01 0.00000000e+00
  5.53068590e+00]
 [1.00000000e+00 2.90000000e+01 2.86671281e-01 0.00000000e+00
  5.83729553e+00]
 [1.00000000e+00 3.00000000e+01 2.77556747e-01 0.00000000e+00
  5.50498629e+00]
 [1.00000000e+00 3.10000000e+01 2.60728776e-01 0.00000000e+00
  5.67329884e+00]
 [1.00000000e+00 3.20000000e+01 2.63771027e-01 0.00000000e+00
  5.72911453e+00]
 [1.00000000e+00 3.30000000e+01 2.58151144e-01 0.00000000e+00
  6.00071096e+00]
 [1.00000000e+00 3.40000000e+01 2.54531115e-01 0.00000000e+00
  5.85542822e+00]
 [1.00000000e+00 3.50000000e+01 2.39213109e-01 0.00000000e+00
  6.02575207e+00]
 [1.00000000e+00 3.60000000e+01 2.32277587e-01 0.00000000e+00
  6.24313211e+00]
 [1.00000000e+00 3.70000000e+01 2.41028637e-01 0.00000000e+00
  6.13102484e+00]
 [1.00000000e+00 3.80000000e+01 2.45280147e-01 0.00000000e+00
  6.36832666e+00]
 [1.00000000e+00 3.90000000e+01 2.19161227e-01 0.00000000e+00
  6.25614166e+00]
 [1.00000000e+00 4.00000000e+01 2.02285454e-01 0.00000000e+00
  6.20438337e+00]
 [1.00000000e+00 4.10000000e+01 2.16712043e-01 0.00000000e+00
  6.66814423e+00]
 [1.00000000e+00 4.20000000e+01 2.02459767e-01 0.00000000e+00
  6.96894217e+00]
 [1.00000000e+00 4.30000000e+01 1.91643015e-01 0.00000000e+00
  6.84031630e+00]
 [1.00000000e+00 4.40000000e+01 1.89078718e-01 0.00000000e+00
  6.83900452e+00]
 [1.00000000e+00 4.50000000e+01 1.70178920e-01 0.00000000e+00
  6.96279526e+00]
 [1.00000000e+00 4.60000000e+01 1.85446545e-01 0.00000000e+00
  7.36610126e+00]
 [1.00000000e+00 4.70000000e+01 1.71708897e-01 0.00000000e+00
  7.06800699e+00]
 [1.00000000e+00 4.80000000e+01 1.52016014e-01 0.00000000e+00
  7.42351675e+00]
 [1.00000000e+00 4.90000000e+01 1.56185105e-01 0.00000000e+00
  7.46893406e+00]
 [1.00000000e+00 5.00000000e+01 1.71078265e-01 0.00000000e+00
  8.00892639e+00]
 [1.00000000e+00 5.10000000e+01 1.33953094e-01 0.00000000e+00
  7.73567677e+00]
 [1.00000000e+00 5.20000000e+01 1.39464185e-01 0.00000000e+00
  7.88073301e+00]
 [1.00000000e+00 5.30000000e+01 1.38921052e-01 0.00000000e+00
  8.11386204e+00]
 [1.00000000e+00 5.40000000e+01 1.26040131e-01 0.00000000e+00
  7.90681171e+00]
 [1.00000000e+00 5.50000000e+01 1.29113600e-01 0.00000000e+00
  8.39498425e+00]
 [1.00000000e+00 5.60000000e+01 1.25058651e-01 0.00000000e+00
  8.03620815e+00]
 [1.00000000e+00 5.70000000e+01 1.17319152e-01 0.00000000e+00
  8.48965359e+00]
 [1.00000000e+00 5.80000000e+01 9.29464251e-02 0.00000000e+00
  9.03112698e+00]
 [1.00000000e+00 5.90000000e+01 1.19108617e-01 0.00000000e+00
  8.71849632e+00]
 [1.00000000e+00 6.00000000e+01 1.00106262e-01 0.00000000e+00
  9.25134563e+00]
 [1.00000000e+00 6.10000000e+01 1.02511741e-01 0.00000000e+00
  8.64664745e+00]
 [1.00000000e+00 6.20000000e+01 9.69169587e-02 0.00000000e+00
  9.07325649e+00]
 [1.00000000e+00 6.30000000e+01 8.81234184e-02 0.00000000e+00
  9.20100975e+00]
 [1.00000000e+00 6.40000000e+01 9.17236656e-02 0.00000000e+00
  9.21248531e+00]
 [1.00000000e+00 6.50000000e+01 9.57230479e-02 0.00000000e+00
  9.67524147e+00]
 [1.00000000e+00 6.60000000e+01 8.95080492e-02 0.00000000e+00
  9.59284210e+00]
 [1.00000000e+00 6.70000000e+01 9.63202715e-02 0.00000000e+00
  9.78663254e+00]
 [1.00000000e+00 6.80000000e+01 1.12153053e-01 0.00000000e+00
  9.68066406e+00]
 [1.00000000e+00 6.90000000e+01 7.58303180e-02 0.00000000e+00
  9.66231441e+00]
 [1.00000000e+00 7.00000000e+01 8.37510750e-02 0.00000000e+00
  1.01081915e+01]
 [1.00000000e+00 7.10000000e+01 7.24602938e-02 0.00000000e+00
  1.07061071e+01]
 [1.00000000e+00 7.20000000e+01 8.22092444e-02 0.00000000e+00
  1.00172930e+01]
 [1.00000000e+00 7.30000000e+01 7.21338093e-02 0.00000000e+00
  1.03673401e+01]
 [1.00000000e+00 7.40000000e+01 7.43681416e-02 0.00000000e+00
  1.02724028e+01]
 [1.00000000e+00 7.50000000e+01 8.09321851e-02 0.00000000e+00
  1.09349670e+01]
 [1.00000000e+00 7.60000000e+01 6.58014417e-02 0.00000000e+00
  1.05983248e+01]]
[75:28499]  loss_total_vae=0.081  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.081  loss_total_vae_epoch=0.071  
Losses: {'total_vae': tensor(0.0665, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0665, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.00000000e+00 1.00000000e+00 6.92772329e-01 0.00000000e+00
  8.99170876e-01]
 [1.00000000e+00 2.00000000e+00 4.43630755e-01 0.00000000e+00
  3.01528788e+00]
 [1.00000000e+00 3.00000000e+00 3.50028694e-01 0.00000000e+00
  3.39058685e+00]
 [1.00000000e+00 4.00000000e+00 3.03678334e-01 0.00000000e+00
  3.48947883e+00]
 [1.00000000e+00 5.00000000e+00 2.89908916e-01 0.00000000e+00
  3.99559569e+00]
 [1.00000000e+00 6.00000000e+00 2.59500504e-01 0.00000000e+00
  4.02565432e+00]
 [1.00000000e+00 7.00000000e+00 2.56480604e-01 0.00000000e+00
  3.94813323e+00]
 [1.00000000e+00 8.00000000e+00 2.39234567e-01 0.00000000e+00
  4.01442099e+00]
 [1.00000000e+00 9.00000000e+00 2.27977157e-01 0.00000000e+00
  4.22430038e+00]
 [1.00000000e+00 1.00000000e+01 2.37352341e-01 0.00000000e+00
  4.43185425e+00]
 [1.00000000e+00 1.10000000e+01 2.16927484e-01 0.00000000e+00
  4.50525761e+00]
 [1.00000000e+00 1.20000000e+01 2.20363230e-01 0.00000000e+00
  4.44228792e+00]
 [1.00000000e+00 1.30000000e+01 2.09068388e-01 0.00000000e+00
  4.66179037e+00]
 [1.00000000e+00 1.40000000e+01 2.04357773e-01 0.00000000e+00
  4.48139954e+00]
 [1.00000000e+00 1.50000000e+01 1.89727500e-01 0.00000000e+00
  4.67815495e+00]
 [1.00000000e+00 1.60000000e+01 1.79508060e-01 0.00000000e+00
  4.68066502e+00]
 [1.00000000e+00 1.70000000e+01 1.68695286e-01 0.00000000e+00
  4.85452175e+00]
 [1.00000000e+00 1.80000000e+01 1.74367577e-01 0.00000000e+00
  4.83069229e+00]
 [1.00000000e+00 1.90000000e+01 1.53472960e-01 0.00000000e+00
  4.90445280e+00]
 [1.00000000e+00 2.00000000e+01 1.46081373e-01 0.00000000e+00
  4.96000528e+00]
 [1.00000000e+00 2.10000000e+01 1.20122150e-01 0.00000000e+00
  5.14042282e+00]
 [1.00000000e+00 2.20000000e+01 1.19896904e-01 0.00000000e+00
  5.07718039e+00]
 [1.00000000e+00 2.30000000e+01 1.17129758e-01 0.00000000e+00
  5.14670515e+00]
 [1.00000000e+00 2.40000000e+01 9.94224399e-02 0.00000000e+00
  5.22992277e+00]
 [1.00000000e+00 2.50000000e+01 8.58300328e-02 0.00000000e+00
  5.18132925e+00]
 [1.00000000e+00 2.60000000e+01 8.64278525e-02 0.00000000e+00
  5.35614824e+00]
 [1.00000000e+00 2.70000000e+01 4.13457960e-01 0.00000000e+00
  5.09576797e+00]
 [1.00000000e+00 2.80000000e+01 3.09257299e-01 0.00000000e+00
  5.53068590e+00]
 [1.00000000e+00 2.90000000e+01 2.86671281e-01 0.00000000e+00
  5.83729553e+00]
 [1.00000000e+00 3.00000000e+01 2.77556747e-01 0.00000000e+00
  5.50498629e+00]
 [1.00000000e+00 3.10000000e+01 2.60728776e-01 0.00000000e+00
  5.67329884e+00]
 [1.00000000e+00 3.20000000e+01 2.63771027e-01 0.00000000e+00
  5.72911453e+00]
 [1.00000000e+00 3.30000000e+01 2.58151144e-01 0.00000000e+00
  6.00071096e+00]
 [1.00000000e+00 3.40000000e+01 2.54531115e-01 0.00000000e+00
  5.85542822e+00]
 [1.00000000e+00 3.50000000e+01 2.39213109e-01 0.00000000e+00
  6.02575207e+00]
 [1.00000000e+00 3.60000000e+01 2.32277587e-01 0.00000000e+00
  6.24313211e+00]
 [1.00000000e+00 3.70000000e+01 2.41028637e-01 0.00000000e+00
  6.13102484e+00]
 [1.00000000e+00 3.80000000e+01 2.45280147e-01 0.00000000e+00
  6.36832666e+00]
 [1.00000000e+00 3.90000000e+01 2.19161227e-01 0.00000000e+00
  6.25614166e+00]
 [1.00000000e+00 4.00000000e+01 2.02285454e-01 0.00000000e+00
  6.20438337e+00]
 [1.00000000e+00 4.10000000e+01 2.16712043e-01 0.00000000e+00
  6.66814423e+00]
 [1.00000000e+00 4.20000000e+01 2.02459767e-01 0.00000000e+00
  6.96894217e+00]
 [1.00000000e+00 4.30000000e+01 1.91643015e-01 0.00000000e+00
  6.84031630e+00]
 [1.00000000e+00 4.40000000e+01 1.89078718e-01 0.00000000e+00
  6.83900452e+00]
 [1.00000000e+00 4.50000000e+01 1.70178920e-01 0.00000000e+00
  6.96279526e+00]
 [1.00000000e+00 4.60000000e+01 1.85446545e-01 0.00000000e+00
  7.36610126e+00]
 [1.00000000e+00 4.70000000e+01 1.71708897e-01 0.00000000e+00
  7.06800699e+00]
 [1.00000000e+00 4.80000000e+01 1.52016014e-01 0.00000000e+00
  7.42351675e+00]
 [1.00000000e+00 4.90000000e+01 1.56185105e-01 0.00000000e+00
  7.46893406e+00]
 [1.00000000e+00 5.00000000e+01 1.71078265e-01 0.00000000e+00
  8.00892639e+00]
 [1.00000000e+00 5.10000000e+01 1.33953094e-01 0.00000000e+00
  7.73567677e+00]
 [1.00000000e+00 5.20000000e+01 1.39464185e-01 0.00000000e+00
  7.88073301e+00]
 [1.00000000e+00 5.30000000e+01 1.38921052e-01 0.00000000e+00
  8.11386204e+00]
 [1.00000000e+00 5.40000000e+01 1.26040131e-01 0.00000000e+00
  7.90681171e+00]
 [1.00000000e+00 5.50000000e+01 1.29113600e-01 0.00000000e+00
  8.39498425e+00]
 [1.00000000e+00 5.60000000e+01 1.25058651e-01 0.00000000e+00
  8.03620815e+00]
 [1.00000000e+00 5.70000000e+01 1.17319152e-01 0.00000000e+00
  8.48965359e+00]
 [1.00000000e+00 5.80000000e+01 9.29464251e-02 0.00000000e+00
  9.03112698e+00]
 [1.00000000e+00 5.90000000e+01 1.19108617e-01 0.00000000e+00
  8.71849632e+00]
 [1.00000000e+00 6.00000000e+01 1.00106262e-01 0.00000000e+00
  9.25134563e+00]
 [1.00000000e+00 6.10000000e+01 1.02511741e-01 0.00000000e+00
  8.64664745e+00]
 [1.00000000e+00 6.20000000e+01 9.69169587e-02 0.00000000e+00
  9.07325649e+00]
 [1.00000000e+00 6.30000000e+01 8.81234184e-02 0.00000000e+00
  9.20100975e+00]
 [1.00000000e+00 6.40000000e+01 9.17236656e-02 0.00000000e+00
  9.21248531e+00]
 [1.00000000e+00 6.50000000e+01 9.57230479e-02 0.00000000e+00
  9.67524147e+00]
 [1.00000000e+00 6.60000000e+01 8.95080492e-02 0.00000000e+00
  9.59284210e+00]
 [1.00000000e+00 6.70000000e+01 9.63202715e-02 0.00000000e+00
  9.78663254e+00]
 [1.00000000e+00 6.80000000e+01 1.12153053e-01 0.00000000e+00
  9.68066406e+00]
 [1.00000000e+00 6.90000000e+01 7.58303180e-02 0.00000000e+00
  9.66231441e+00]
 [1.00000000e+00 7.00000000e+01 8.37510750e-02 0.00000000e+00
  1.01081915e+01]
 [1.00000000e+00 7.10000000e+01 7.24602938e-02 0.00000000e+00
  1.07061071e+01]
 [1.00000000e+00 7.20000000e+01 8.22092444e-02 0.00000000e+00
  1.00172930e+01]
 [1.00000000e+00 7.30000000e+01 7.21338093e-02 0.00000000e+00
  1.03673401e+01]
 [1.00000000e+00 7.40000000e+01 7.43681416e-02 0.00000000e+00
  1.02724028e+01]
 [1.00000000e+00 7.50000000e+01 8.09321851e-02 0.00000000e+00
  1.09349670e+01]
 [1.00000000e+00 7.60000000e+01 6.58014417e-02 0.00000000e+00
  1.05983248e+01]
 [1.00000000e+00 7.70000000e+01 6.64683133e-02 0.00000000e+00
  1.08141251e+01]]
[76:28874]  loss_total_vae=0.057  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.057  loss_total_vae_epoch=0.069  
Losses: {'total_vae': tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0689, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.00000000e+00 1.00000000e+00 6.92772329e-01 0.00000000e+00
  8.99170876e-01]
 [1.00000000e+00 2.00000000e+00 4.43630755e-01 0.00000000e+00
  3.01528788e+00]
 [1.00000000e+00 3.00000000e+00 3.50028694e-01 0.00000000e+00
  3.39058685e+00]
 [1.00000000e+00 4.00000000e+00 3.03678334e-01 0.00000000e+00
  3.48947883e+00]
 [1.00000000e+00 5.00000000e+00 2.89908916e-01 0.00000000e+00
  3.99559569e+00]
 [1.00000000e+00 6.00000000e+00 2.59500504e-01 0.00000000e+00
  4.02565432e+00]
 [1.00000000e+00 7.00000000e+00 2.56480604e-01 0.00000000e+00
  3.94813323e+00]
 [1.00000000e+00 8.00000000e+00 2.39234567e-01 0.00000000e+00
  4.01442099e+00]
 [1.00000000e+00 9.00000000e+00 2.27977157e-01 0.00000000e+00
  4.22430038e+00]
 [1.00000000e+00 1.00000000e+01 2.37352341e-01 0.00000000e+00
  4.43185425e+00]
 [1.00000000e+00 1.10000000e+01 2.16927484e-01 0.00000000e+00
  4.50525761e+00]
 [1.00000000e+00 1.20000000e+01 2.20363230e-01 0.00000000e+00
  4.44228792e+00]
 [1.00000000e+00 1.30000000e+01 2.09068388e-01 0.00000000e+00
  4.66179037e+00]
 [1.00000000e+00 1.40000000e+01 2.04357773e-01 0.00000000e+00
  4.48139954e+00]
 [1.00000000e+00 1.50000000e+01 1.89727500e-01 0.00000000e+00
  4.67815495e+00]
 [1.00000000e+00 1.60000000e+01 1.79508060e-01 0.00000000e+00
  4.68066502e+00]
 [1.00000000e+00 1.70000000e+01 1.68695286e-01 0.00000000e+00
  4.85452175e+00]
 [1.00000000e+00 1.80000000e+01 1.74367577e-01 0.00000000e+00
  4.83069229e+00]
 [1.00000000e+00 1.90000000e+01 1.53472960e-01 0.00000000e+00
  4.90445280e+00]
 [1.00000000e+00 2.00000000e+01 1.46081373e-01 0.00000000e+00
  4.96000528e+00]
 [1.00000000e+00 2.10000000e+01 1.20122150e-01 0.00000000e+00
  5.14042282e+00]
 [1.00000000e+00 2.20000000e+01 1.19896904e-01 0.00000000e+00
  5.07718039e+00]
 [1.00000000e+00 2.30000000e+01 1.17129758e-01 0.00000000e+00
  5.14670515e+00]
 [1.00000000e+00 2.40000000e+01 9.94224399e-02 0.00000000e+00
  5.22992277e+00]
 [1.00000000e+00 2.50000000e+01 8.58300328e-02 0.00000000e+00
  5.18132925e+00]
 [1.00000000e+00 2.60000000e+01 8.64278525e-02 0.00000000e+00
  5.35614824e+00]
 [1.00000000e+00 2.70000000e+01 4.13457960e-01 0.00000000e+00
  5.09576797e+00]
 [1.00000000e+00 2.80000000e+01 3.09257299e-01 0.00000000e+00
  5.53068590e+00]
 [1.00000000e+00 2.90000000e+01 2.86671281e-01 0.00000000e+00
  5.83729553e+00]
 [1.00000000e+00 3.00000000e+01 2.77556747e-01 0.00000000e+00
  5.50498629e+00]
 [1.00000000e+00 3.10000000e+01 2.60728776e-01 0.00000000e+00
  5.67329884e+00]
 [1.00000000e+00 3.20000000e+01 2.63771027e-01 0.00000000e+00
  5.72911453e+00]
 [1.00000000e+00 3.30000000e+01 2.58151144e-01 0.00000000e+00
  6.00071096e+00]
 [1.00000000e+00 3.40000000e+01 2.54531115e-01 0.00000000e+00
  5.85542822e+00]
 [1.00000000e+00 3.50000000e+01 2.39213109e-01 0.00000000e+00
  6.02575207e+00]
 [1.00000000e+00 3.60000000e+01 2.32277587e-01 0.00000000e+00
  6.24313211e+00]
 [1.00000000e+00 3.70000000e+01 2.41028637e-01 0.00000000e+00
  6.13102484e+00]
 [1.00000000e+00 3.80000000e+01 2.45280147e-01 0.00000000e+00
  6.36832666e+00]
 [1.00000000e+00 3.90000000e+01 2.19161227e-01 0.00000000e+00
  6.25614166e+00]
 [1.00000000e+00 4.00000000e+01 2.02285454e-01 0.00000000e+00
  6.20438337e+00]
 [1.00000000e+00 4.10000000e+01 2.16712043e-01 0.00000000e+00
  6.66814423e+00]
 [1.00000000e+00 4.20000000e+01 2.02459767e-01 0.00000000e+00
  6.96894217e+00]
 [1.00000000e+00 4.30000000e+01 1.91643015e-01 0.00000000e+00
  6.84031630e+00]
 [1.00000000e+00 4.40000000e+01 1.89078718e-01 0.00000000e+00
  6.83900452e+00]
 [1.00000000e+00 4.50000000e+01 1.70178920e-01 0.00000000e+00
  6.96279526e+00]
 [1.00000000e+00 4.60000000e+01 1.85446545e-01 0.00000000e+00
  7.36610126e+00]
 [1.00000000e+00 4.70000000e+01 1.71708897e-01 0.00000000e+00
  7.06800699e+00]
 [1.00000000e+00 4.80000000e+01 1.52016014e-01 0.00000000e+00
  7.42351675e+00]
 [1.00000000e+00 4.90000000e+01 1.56185105e-01 0.00000000e+00
  7.46893406e+00]
 [1.00000000e+00 5.00000000e+01 1.71078265e-01 0.00000000e+00
  8.00892639e+00]
 [1.00000000e+00 5.10000000e+01 1.33953094e-01 0.00000000e+00
  7.73567677e+00]
 [1.00000000e+00 5.20000000e+01 1.39464185e-01 0.00000000e+00
  7.88073301e+00]
 [1.00000000e+00 5.30000000e+01 1.38921052e-01 0.00000000e+00
  8.11386204e+00]
 [1.00000000e+00 5.40000000e+01 1.26040131e-01 0.00000000e+00
  7.90681171e+00]
 [1.00000000e+00 5.50000000e+01 1.29113600e-01 0.00000000e+00
  8.39498425e+00]
 [1.00000000e+00 5.60000000e+01 1.25058651e-01 0.00000000e+00
  8.03620815e+00]
 [1.00000000e+00 5.70000000e+01 1.17319152e-01 0.00000000e+00
  8.48965359e+00]
 [1.00000000e+00 5.80000000e+01 9.29464251e-02 0.00000000e+00
  9.03112698e+00]
 [1.00000000e+00 5.90000000e+01 1.19108617e-01 0.00000000e+00
  8.71849632e+00]
 [1.00000000e+00 6.00000000e+01 1.00106262e-01 0.00000000e+00
  9.25134563e+00]
 [1.00000000e+00 6.10000000e+01 1.02511741e-01 0.00000000e+00
  8.64664745e+00]
 [1.00000000e+00 6.20000000e+01 9.69169587e-02 0.00000000e+00
  9.07325649e+00]
 [1.00000000e+00 6.30000000e+01 8.81234184e-02 0.00000000e+00
  9.20100975e+00]
 [1.00000000e+00 6.40000000e+01 9.17236656e-02 0.00000000e+00
  9.21248531e+00]
 [1.00000000e+00 6.50000000e+01 9.57230479e-02 0.00000000e+00
  9.67524147e+00]
 [1.00000000e+00 6.60000000e+01 8.95080492e-02 0.00000000e+00
  9.59284210e+00]
 [1.00000000e+00 6.70000000e+01 9.63202715e-02 0.00000000e+00
  9.78663254e+00]
 [1.00000000e+00 6.80000000e+01 1.12153053e-01 0.00000000e+00
  9.68066406e+00]
 [1.00000000e+00 6.90000000e+01 7.58303180e-02 0.00000000e+00
  9.66231441e+00]
 [1.00000000e+00 7.00000000e+01 8.37510750e-02 0.00000000e+00
  1.01081915e+01]
 [1.00000000e+00 7.10000000e+01 7.24602938e-02 0.00000000e+00
  1.07061071e+01]
 [1.00000000e+00 7.20000000e+01 8.22092444e-02 0.00000000e+00
  1.00172930e+01]
 [1.00000000e+00 7.30000000e+01 7.21338093e-02 0.00000000e+00
  1.03673401e+01]
 [1.00000000e+00 7.40000000e+01 7.43681416e-02 0.00000000e+00
  1.02724028e+01]
 [1.00000000e+00 7.50000000e+01 8.09321851e-02 0.00000000e+00
  1.09349670e+01]
 [1.00000000e+00 7.60000000e+01 6.58014417e-02 0.00000000e+00
  1.05983248e+01]
 [1.00000000e+00 7.70000000e+01 6.64683133e-02 0.00000000e+00
  1.08141251e+01]
 [1.00000000e+00 7.80000000e+01 6.88827336e-02 0.00000000e+00
  1.09721508e+01]]
[77:29249]  loss_total_vae=0.069  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.069  loss_total_vae_epoch=0.067  
Losses: {'total_vae': tensor(0.0653, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0653, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.00000000e+00 1.00000000e+00 6.92772329e-01 0.00000000e+00
  8.99170876e-01]
 [1.00000000e+00 2.00000000e+00 4.43630755e-01 0.00000000e+00
  3.01528788e+00]
 [1.00000000e+00 3.00000000e+00 3.50028694e-01 0.00000000e+00
  3.39058685e+00]
 [1.00000000e+00 4.00000000e+00 3.03678334e-01 0.00000000e+00
  3.48947883e+00]
 [1.00000000e+00 5.00000000e+00 2.89908916e-01 0.00000000e+00
  3.99559569e+00]
 [1.00000000e+00 6.00000000e+00 2.59500504e-01 0.00000000e+00
  4.02565432e+00]
 [1.00000000e+00 7.00000000e+00 2.56480604e-01 0.00000000e+00
  3.94813323e+00]
 [1.00000000e+00 8.00000000e+00 2.39234567e-01 0.00000000e+00
  4.01442099e+00]
 [1.00000000e+00 9.00000000e+00 2.27977157e-01 0.00000000e+00
  4.22430038e+00]
 [1.00000000e+00 1.00000000e+01 2.37352341e-01 0.00000000e+00
  4.43185425e+00]
 [1.00000000e+00 1.10000000e+01 2.16927484e-01 0.00000000e+00
  4.50525761e+00]
 [1.00000000e+00 1.20000000e+01 2.20363230e-01 0.00000000e+00
  4.44228792e+00]
 [1.00000000e+00 1.30000000e+01 2.09068388e-01 0.00000000e+00
  4.66179037e+00]
 [1.00000000e+00 1.40000000e+01 2.04357773e-01 0.00000000e+00
  4.48139954e+00]
 [1.00000000e+00 1.50000000e+01 1.89727500e-01 0.00000000e+00
  4.67815495e+00]
 [1.00000000e+00 1.60000000e+01 1.79508060e-01 0.00000000e+00
  4.68066502e+00]
 [1.00000000e+00 1.70000000e+01 1.68695286e-01 0.00000000e+00
  4.85452175e+00]
 [1.00000000e+00 1.80000000e+01 1.74367577e-01 0.00000000e+00
  4.83069229e+00]
 [1.00000000e+00 1.90000000e+01 1.53472960e-01 0.00000000e+00
  4.90445280e+00]
 [1.00000000e+00 2.00000000e+01 1.46081373e-01 0.00000000e+00
  4.96000528e+00]
 [1.00000000e+00 2.10000000e+01 1.20122150e-01 0.00000000e+00
  5.14042282e+00]
 [1.00000000e+00 2.20000000e+01 1.19896904e-01 0.00000000e+00
  5.07718039e+00]
 [1.00000000e+00 2.30000000e+01 1.17129758e-01 0.00000000e+00
  5.14670515e+00]
 [1.00000000e+00 2.40000000e+01 9.94224399e-02 0.00000000e+00
  5.22992277e+00]
 [1.00000000e+00 2.50000000e+01 8.58300328e-02 0.00000000e+00
  5.18132925e+00]
 [1.00000000e+00 2.60000000e+01 8.64278525e-02 0.00000000e+00
  5.35614824e+00]
 [1.00000000e+00 2.70000000e+01 4.13457960e-01 0.00000000e+00
  5.09576797e+00]
 [1.00000000e+00 2.80000000e+01 3.09257299e-01 0.00000000e+00
  5.53068590e+00]
 [1.00000000e+00 2.90000000e+01 2.86671281e-01 0.00000000e+00
  5.83729553e+00]
 [1.00000000e+00 3.00000000e+01 2.77556747e-01 0.00000000e+00
  5.50498629e+00]
 [1.00000000e+00 3.10000000e+01 2.60728776e-01 0.00000000e+00
  5.67329884e+00]
 [1.00000000e+00 3.20000000e+01 2.63771027e-01 0.00000000e+00
  5.72911453e+00]
 [1.00000000e+00 3.30000000e+01 2.58151144e-01 0.00000000e+00
  6.00071096e+00]
 [1.00000000e+00 3.40000000e+01 2.54531115e-01 0.00000000e+00
  5.85542822e+00]
 [1.00000000e+00 3.50000000e+01 2.39213109e-01 0.00000000e+00
  6.02575207e+00]
 [1.00000000e+00 3.60000000e+01 2.32277587e-01 0.00000000e+00
  6.24313211e+00]
 [1.00000000e+00 3.70000000e+01 2.41028637e-01 0.00000000e+00
  6.13102484e+00]
 [1.00000000e+00 3.80000000e+01 2.45280147e-01 0.00000000e+00
  6.36832666e+00]
 [1.00000000e+00 3.90000000e+01 2.19161227e-01 0.00000000e+00
  6.25614166e+00]
 [1.00000000e+00 4.00000000e+01 2.02285454e-01 0.00000000e+00
  6.20438337e+00]
 [1.00000000e+00 4.10000000e+01 2.16712043e-01 0.00000000e+00
  6.66814423e+00]
 [1.00000000e+00 4.20000000e+01 2.02459767e-01 0.00000000e+00
  6.96894217e+00]
 [1.00000000e+00 4.30000000e+01 1.91643015e-01 0.00000000e+00
  6.84031630e+00]
 [1.00000000e+00 4.40000000e+01 1.89078718e-01 0.00000000e+00
  6.83900452e+00]
 [1.00000000e+00 4.50000000e+01 1.70178920e-01 0.00000000e+00
  6.96279526e+00]
 [1.00000000e+00 4.60000000e+01 1.85446545e-01 0.00000000e+00
  7.36610126e+00]
 [1.00000000e+00 4.70000000e+01 1.71708897e-01 0.00000000e+00
  7.06800699e+00]
 [1.00000000e+00 4.80000000e+01 1.52016014e-01 0.00000000e+00
  7.42351675e+00]
 [1.00000000e+00 4.90000000e+01 1.56185105e-01 0.00000000e+00
  7.46893406e+00]
 [1.00000000e+00 5.00000000e+01 1.71078265e-01 0.00000000e+00
  8.00892639e+00]
 [1.00000000e+00 5.10000000e+01 1.33953094e-01 0.00000000e+00
  7.73567677e+00]
 [1.00000000e+00 5.20000000e+01 1.39464185e-01 0.00000000e+00
  7.88073301e+00]
 [1.00000000e+00 5.30000000e+01 1.38921052e-01 0.00000000e+00
  8.11386204e+00]
 [1.00000000e+00 5.40000000e+01 1.26040131e-01 0.00000000e+00
  7.90681171e+00]
 [1.00000000e+00 5.50000000e+01 1.29113600e-01 0.00000000e+00
  8.39498425e+00]
 [1.00000000e+00 5.60000000e+01 1.25058651e-01 0.00000000e+00
  8.03620815e+00]
 [1.00000000e+00 5.70000000e+01 1.17319152e-01 0.00000000e+00
  8.48965359e+00]
 [1.00000000e+00 5.80000000e+01 9.29464251e-02 0.00000000e+00
  9.03112698e+00]
 [1.00000000e+00 5.90000000e+01 1.19108617e-01 0.00000000e+00
  8.71849632e+00]
 [1.00000000e+00 6.00000000e+01 1.00106262e-01 0.00000000e+00
  9.25134563e+00]
 [1.00000000e+00 6.10000000e+01 1.02511741e-01 0.00000000e+00
  8.64664745e+00]
 [1.00000000e+00 6.20000000e+01 9.69169587e-02 0.00000000e+00
  9.07325649e+00]
 [1.00000000e+00 6.30000000e+01 8.81234184e-02 0.00000000e+00
  9.20100975e+00]
 [1.00000000e+00 6.40000000e+01 9.17236656e-02 0.00000000e+00
  9.21248531e+00]
 [1.00000000e+00 6.50000000e+01 9.57230479e-02 0.00000000e+00
  9.67524147e+00]
 [1.00000000e+00 6.60000000e+01 8.95080492e-02 0.00000000e+00
  9.59284210e+00]
 [1.00000000e+00 6.70000000e+01 9.63202715e-02 0.00000000e+00
  9.78663254e+00]
 [1.00000000e+00 6.80000000e+01 1.12153053e-01 0.00000000e+00
  9.68066406e+00]
 [1.00000000e+00 6.90000000e+01 7.58303180e-02 0.00000000e+00
  9.66231441e+00]
 [1.00000000e+00 7.00000000e+01 8.37510750e-02 0.00000000e+00
  1.01081915e+01]
 [1.00000000e+00 7.10000000e+01 7.24602938e-02 0.00000000e+00
  1.07061071e+01]
 [1.00000000e+00 7.20000000e+01 8.22092444e-02 0.00000000e+00
  1.00172930e+01]
 [1.00000000e+00 7.30000000e+01 7.21338093e-02 0.00000000e+00
  1.03673401e+01]
 [1.00000000e+00 7.40000000e+01 7.43681416e-02 0.00000000e+00
  1.02724028e+01]
 [1.00000000e+00 7.50000000e+01 8.09321851e-02 0.00000000e+00
  1.09349670e+01]
 [1.00000000e+00 7.60000000e+01 6.58014417e-02 0.00000000e+00
  1.05983248e+01]
 [1.00000000e+00 7.70000000e+01 6.64683133e-02 0.00000000e+00
  1.08141251e+01]
 [1.00000000e+00 7.80000000e+01 6.88827336e-02 0.00000000e+00
  1.09721508e+01]
 [1.00000000e+00 7.90000000e+01 6.53063208e-02 0.00000000e+00
  1.05611935e+01]]
[78:29624]  loss_total_vae=0.083  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.083  loss_total_vae_epoch=0.066  
Losses: {'total_vae': tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>), 'total': 0, 'prediction': tensor(0., device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(0.0499, device='cuda:0', grad_fn=<MulBackward0>)}
Data format:
[[1.00000000e+00 1.00000000e+00 6.92772329e-01 0.00000000e+00
  8.99170876e-01]
 [1.00000000e+00 2.00000000e+00 4.43630755e-01 0.00000000e+00
  3.01528788e+00]
 [1.00000000e+00 3.00000000e+00 3.50028694e-01 0.00000000e+00
  3.39058685e+00]
 [1.00000000e+00 4.00000000e+00 3.03678334e-01 0.00000000e+00
  3.48947883e+00]
 [1.00000000e+00 5.00000000e+00 2.89908916e-01 0.00000000e+00
  3.99559569e+00]
 [1.00000000e+00 6.00000000e+00 2.59500504e-01 0.00000000e+00
  4.02565432e+00]
 [1.00000000e+00 7.00000000e+00 2.56480604e-01 0.00000000e+00
  3.94813323e+00]
 [1.00000000e+00 8.00000000e+00 2.39234567e-01 0.00000000e+00
  4.01442099e+00]
 [1.00000000e+00 9.00000000e+00 2.27977157e-01 0.00000000e+00
  4.22430038e+00]
 [1.00000000e+00 1.00000000e+01 2.37352341e-01 0.00000000e+00
  4.43185425e+00]
 [1.00000000e+00 1.10000000e+01 2.16927484e-01 0.00000000e+00
  4.50525761e+00]
 [1.00000000e+00 1.20000000e+01 2.20363230e-01 0.00000000e+00
  4.44228792e+00]
 [1.00000000e+00 1.30000000e+01 2.09068388e-01 0.00000000e+00
  4.66179037e+00]
 [1.00000000e+00 1.40000000e+01 2.04357773e-01 0.00000000e+00
  4.48139954e+00]
 [1.00000000e+00 1.50000000e+01 1.89727500e-01 0.00000000e+00
  4.67815495e+00]
 [1.00000000e+00 1.60000000e+01 1.79508060e-01 0.00000000e+00
  4.68066502e+00]
 [1.00000000e+00 1.70000000e+01 1.68695286e-01 0.00000000e+00
  4.85452175e+00]
 [1.00000000e+00 1.80000000e+01 1.74367577e-01 0.00000000e+00
  4.83069229e+00]
 [1.00000000e+00 1.90000000e+01 1.53472960e-01 0.00000000e+00
  4.90445280e+00]
 [1.00000000e+00 2.00000000e+01 1.46081373e-01 0.00000000e+00
  4.96000528e+00]
 [1.00000000e+00 2.10000000e+01 1.20122150e-01 0.00000000e+00
  5.14042282e+00]
 [1.00000000e+00 2.20000000e+01 1.19896904e-01 0.00000000e+00
  5.07718039e+00]
 [1.00000000e+00 2.30000000e+01 1.17129758e-01 0.00000000e+00
  5.14670515e+00]
 [1.00000000e+00 2.40000000e+01 9.94224399e-02 0.00000000e+00
  5.22992277e+00]
 [1.00000000e+00 2.50000000e+01 8.58300328e-02 0.00000000e+00
  5.18132925e+00]
 [1.00000000e+00 2.60000000e+01 8.64278525e-02 0.00000000e+00
  5.35614824e+00]
 [1.00000000e+00 2.70000000e+01 4.13457960e-01 0.00000000e+00
  5.09576797e+00]
 [1.00000000e+00 2.80000000e+01 3.09257299e-01 0.00000000e+00
  5.53068590e+00]
 [1.00000000e+00 2.90000000e+01 2.86671281e-01 0.00000000e+00
  5.83729553e+00]
 [1.00000000e+00 3.00000000e+01 2.77556747e-01 0.00000000e+00
  5.50498629e+00]
 [1.00000000e+00 3.10000000e+01 2.60728776e-01 0.00000000e+00
  5.67329884e+00]
 [1.00000000e+00 3.20000000e+01 2.63771027e-01 0.00000000e+00
  5.72911453e+00]
 [1.00000000e+00 3.30000000e+01 2.58151144e-01 0.00000000e+00
  6.00071096e+00]
 [1.00000000e+00 3.40000000e+01 2.54531115e-01 0.00000000e+00
  5.85542822e+00]
 [1.00000000e+00 3.50000000e+01 2.39213109e-01 0.00000000e+00
  6.02575207e+00]
 [1.00000000e+00 3.60000000e+01 2.32277587e-01 0.00000000e+00
  6.24313211e+00]
 [1.00000000e+00 3.70000000e+01 2.41028637e-01 0.00000000e+00
  6.13102484e+00]
 [1.00000000e+00 3.80000000e+01 2.45280147e-01 0.00000000e+00
  6.36832666e+00]
 [1.00000000e+00 3.90000000e+01 2.19161227e-01 0.00000000e+00
  6.25614166e+00]
 [1.00000000e+00 4.00000000e+01 2.02285454e-01 0.00000000e+00
  6.20438337e+00]
 [1.00000000e+00 4.10000000e+01 2.16712043e-01 0.00000000e+00
  6.66814423e+00]
 [1.00000000e+00 4.20000000e+01 2.02459767e-01 0.00000000e+00
  6.96894217e+00]
 [1.00000000e+00 4.30000000e+01 1.91643015e-01 0.00000000e+00
  6.84031630e+00]
 [1.00000000e+00 4.40000000e+01 1.89078718e-01 0.00000000e+00
  6.83900452e+00]
 [1.00000000e+00 4.50000000e+01 1.70178920e-01 0.00000000e+00
  6.96279526e+00]
 [1.00000000e+00 4.60000000e+01 1.85446545e-01 0.00000000e+00
  7.36610126e+00]
 [1.00000000e+00 4.70000000e+01 1.71708897e-01 0.00000000e+00
  7.06800699e+00]
 [1.00000000e+00 4.80000000e+01 1.52016014e-01 0.00000000e+00
  7.42351675e+00]
 [1.00000000e+00 4.90000000e+01 1.56185105e-01 0.00000000e+00
  7.46893406e+00]
 [1.00000000e+00 5.00000000e+01 1.71078265e-01 0.00000000e+00
  8.00892639e+00]
 [1.00000000e+00 5.10000000e+01 1.33953094e-01 0.00000000e+00
  7.73567677e+00]
 [1.00000000e+00 5.20000000e+01 1.39464185e-01 0.00000000e+00
  7.88073301e+00]
 [1.00000000e+00 5.30000000e+01 1.38921052e-01 0.00000000e+00
  8.11386204e+00]
 [1.00000000e+00 5.40000000e+01 1.26040131e-01 0.00000000e+00
  7.90681171e+00]
 [1.00000000e+00 5.50000000e+01 1.29113600e-01 0.00000000e+00
  8.39498425e+00]
 [1.00000000e+00 5.60000000e+01 1.25058651e-01 0.00000000e+00
  8.03620815e+00]
 [1.00000000e+00 5.70000000e+01 1.17319152e-01 0.00000000e+00
  8.48965359e+00]
 [1.00000000e+00 5.80000000e+01 9.29464251e-02 0.00000000e+00
  9.03112698e+00]
 [1.00000000e+00 5.90000000e+01 1.19108617e-01 0.00000000e+00
  8.71849632e+00]
 [1.00000000e+00 6.00000000e+01 1.00106262e-01 0.00000000e+00
  9.25134563e+00]
 [1.00000000e+00 6.10000000e+01 1.02511741e-01 0.00000000e+00
  8.64664745e+00]
 [1.00000000e+00 6.20000000e+01 9.69169587e-02 0.00000000e+00
  9.07325649e+00]
 [1.00000000e+00 6.30000000e+01 8.81234184e-02 0.00000000e+00
  9.20100975e+00]
 [1.00000000e+00 6.40000000e+01 9.17236656e-02 0.00000000e+00
  9.21248531e+00]
 [1.00000000e+00 6.50000000e+01 9.57230479e-02 0.00000000e+00
  9.67524147e+00]
 [1.00000000e+00 6.60000000e+01 8.95080492e-02 0.00000000e+00
  9.59284210e+00]
 [1.00000000e+00 6.70000000e+01 9.63202715e-02 0.00000000e+00
  9.78663254e+00]
 [1.00000000e+00 6.80000000e+01 1.12153053e-01 0.00000000e+00
  9.68066406e+00]
 [1.00000000e+00 6.90000000e+01 7.58303180e-02 0.00000000e+00
  9.66231441e+00]
 [1.00000000e+00 7.00000000e+01 8.37510750e-02 0.00000000e+00
  1.01081915e+01]
 [1.00000000e+00 7.10000000e+01 7.24602938e-02 0.00000000e+00
  1.07061071e+01]
 [1.00000000e+00 7.20000000e+01 8.22092444e-02 0.00000000e+00
  1.00172930e+01]
 [1.00000000e+00 7.30000000e+01 7.21338093e-02 0.00000000e+00
  1.03673401e+01]
 [1.00000000e+00 7.40000000e+01 7.43681416e-02 0.00000000e+00
  1.02724028e+01]
 [1.00000000e+00 7.50000000e+01 8.09321851e-02 0.00000000e+00
  1.09349670e+01]
 [1.00000000e+00 7.60000000e+01 6.58014417e-02 0.00000000e+00
  1.05983248e+01]
 [1.00000000e+00 7.70000000e+01 6.64683133e-02 0.00000000e+00
  1.08141251e+01]
 [1.00000000e+00 7.80000000e+01 6.88827336e-02 0.00000000e+00
  1.09721508e+01]
 [1.00000000e+00 7.90000000e+01 6.53063208e-02 0.00000000e+00
  1.05611935e+01]
 [1.00000000e+00 8.00000000e+01 4.99391854e-02 0.00000000e+00
  1.11020145e+01]]
[79:29999]  loss_total_vae=0.100  loss_total=0.000  loss_prediction=0.000  loss_true_values=0.100  loss_total_vae_epoch=0.065  
